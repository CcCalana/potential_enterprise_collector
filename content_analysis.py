#!/usr/bin/env python3
"""
åŸºäºç°æœ‰æ•°æ®çš„ä¼ä¸šä¿¡æ¯åˆ†æå·¥å…·
å³ä½¿æ²¡æœ‰æ­£æ–‡å†…å®¹ï¼Œä¹Ÿèƒ½ä»æ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯ä¸­æå–æœ‰ä»·å€¼çš„ä¼ä¸šä¿¡æ¯
"""

import sys
import re
from typing import List, Dict, Any

sys.path.insert(0, '.')

from app.config import SessionLocal
from app.models import XHSNote
from loguru import logger

class EnterpriseAnalyzer:
    """ä¼ä¸šä¿¡æ¯åˆ†æå™¨"""
    
    def __init__(self):
        # ä¼ä¸šå…³é”®è¯æ¨¡å¼
        self.enterprise_patterns = [
            r'(.*?)(å…¬å¸|ä¼ä¸š|é›†å›¢|ç§‘æŠ€|æœ‰é™å…¬å¸|è‚¡ä»½|å®ä¸š)',
            r'(.*?)(å·¥ä¸šå›­åŒº|äº§ä¸šå›­|ç§‘æŠ€å›­)',
            r'(.*?)(æ‹›è˜|å…¥èŒ|å·¥ä½œ|å²—ä½|èŒä½)',
            r'(.*?)(æŠ•èµ„|èèµ„|ä¸Šå¸‚|IPO)',
            r'(.*?)(AI|äººå·¥æ™ºèƒ½|å¤§æ•°æ®|äº‘è®¡ç®—|åŒºå—é“¾)',
            r'(.*?)(ç”Ÿç‰©åŒ»è¯|åŒ»ç–—|å¥åº·|åˆ¶è¯)',
            r'(.*?)(æ–°èƒ½æº|ç¯ä¿|ç»¿è‰²)',
            r'(.*?)(é‡‘è|é“¶è¡Œ|ä¿é™©|è¯åˆ¸)',
            r'(.*?)(åˆ¶é€ |ç”Ÿäº§|å·¥å‚|è½¦é—´)',
            r'(.*?)(ç ”å‘|æŠ€æœ¯|åˆ›æ–°|ä¸“åˆ©)'
        ]
        
        # åœ°åŒºå…³é”®è¯
        self.location_patterns = [
            r'è‹å·å·¥ä¸šå›­åŒº',
            r'è‹å·å›­åŒº',
            r'å›­åŒº',
            r'è‹å·',
            r'æ±Ÿè‹'
        ]
    
    def extract_enterprise_info(self, note: XHSNote) -> Dict[str, Any]:
        """ä»ç¬”è®°ä¸­æå–ä¼ä¸šä¿¡æ¯"""
        title = str(note.title or "")
        info = {
            'note_id': note.note_id,
            'title': title,
            'author': note.user_name,
            'likes': note.like_count or 0,
            'collects': note.collect_count or 0,
            'comments': note.comment_count or 0,
            'url': note.url,
            'enterprise_keywords': [],
            'location_keywords': [],
            'category': 'unknown',
            'confidence': 0.0
        }
        
        # æå–ä¼ä¸šå…³é”®è¯
        for pattern in self.enterprise_patterns:
            matches = re.findall(pattern, title, re.IGNORECASE)
            if matches:
                info['enterprise_keywords'].extend(matches)
        
        # æå–åœ°åŒºå…³é”®è¯
        for pattern in self.location_patterns:
            if re.search(pattern, title, re.IGNORECASE):
                info['location_keywords'].append(pattern)
        
        # åˆ†ç±»åˆ¤æ–­
        info['category'] = self._categorize_note(title)
        
        # è®¡ç®—ç½®ä¿¡åº¦
        info['confidence'] = self._calculate_confidence(title, info)
        
        return info
    
    def _categorize_note(self, title: str) -> str:
        """å¯¹ç¬”è®°è¿›è¡Œåˆ†ç±»"""
        title_lower = title.lower()
        
        if any(keyword in title_lower for keyword in ['æ‹›è˜', 'å…¥èŒ', 'å·¥ä½œ', 'å²—ä½', 'èŒä½', 'é¢è¯•']):
            return 'recruitment'
        elif any(keyword in title_lower for keyword in ['å…¬å¸', 'ä¼ä¸š', 'é›†å›¢', 'ç§‘æŠ€']):
            return 'company'
        elif any(keyword in title_lower for keyword in ['æ”¿ç­–', 'è¡¥è´´', 'æ‰¶æŒ', 'ä¼˜æƒ ']):
            return 'policy'
        elif any(keyword in title_lower for keyword in ['æŠ•èµ„', 'èèµ„', 'ä¸Šå¸‚', 'ipo']):
            return 'investment'
        elif any(keyword in title_lower for keyword in ['ai', 'äººå·¥æ™ºèƒ½', 'å¤§æ•°æ®', 'äº‘è®¡ç®—']):
            return 'technology'
        elif any(keyword in title_lower for keyword in ['æ—…æ¸¸', 'æ”»ç•¥', 'æ™¯ç‚¹', 'æ¸¸ç©']):
            return 'tourism'
        elif any(keyword in title_lower for keyword in ['ç”Ÿæ´»', 'å±…ä½', 'æˆ¿ç§Ÿ', 'ç§Ÿæˆ¿']):
            return 'lifestyle'
        else:
            return 'general'
    
    def _calculate_confidence(self, title: str, info: Dict[str, Any]) -> float:
        """è®¡ç®—ä¼ä¸šç›¸å…³æ€§ç½®ä¿¡åº¦"""
        confidence = 0.0
        
        # åŸºäºå…³é”®è¯æ•°é‡
        confidence += len(info['enterprise_keywords']) * 0.3
        confidence += len(info['location_keywords']) * 0.2
        
        # åŸºäºåˆ†ç±»
        category_weights = {
            'company': 0.8,
            'recruitment': 0.7,
            'technology': 0.6,
            'investment': 0.6,
            'policy': 0.5,
            'tourism': 0.2,
            'lifestyle': 0.1,
            'general': 0.1
        }
        confidence += category_weights.get(info['category'], 0.1)
        
        # åŸºäºçƒ­åº¦ï¼ˆé«˜çƒ­åº¦å†…å®¹æ›´å¯èƒ½æœ‰ä»·å€¼ï¼‰
        likes = info['likes']
        if likes > 1000:
            confidence += 0.3
        elif likes > 500:
            confidence += 0.2
        elif likes > 100:
            confidence += 0.1
        
        return min(confidence, 1.0)  # é™åˆ¶åœ¨0-1ä¹‹é—´

def analyze_enterprise_notes():
    """åˆ†ææ•°æ®åº“ä¸­çš„ä¼ä¸šç¬”è®°"""
    analyzer = EnterpriseAnalyzer()
    
    with SessionLocal() as db:
        # è·å–æ‰€æœ‰ç¬”è®°
        notes = db.query(XHSNote).order_by(XHSNote.like_count.desc()).all()
        
        logger.info("å¼€å§‹åˆ†æ {} æ¡ç¬”è®°", len(notes))
        
        # åˆ†ææ¯æ¡ç¬”è®°
        results = []
        for note in notes:
            info = analyzer.extract_enterprise_info(note)
            results.append(info)
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        results.sort(key=lambda x: x['confidence'], reverse=True)
        
        # è¾“å‡ºé«˜ä»·å€¼ä¼ä¸šä¿¡æ¯
        print("\nğŸ¢ é«˜ä»·å€¼ä¼ä¸šç›¸å…³ç¬”è®° (ç½®ä¿¡åº¦ > 0.5):")
        print("=" * 80)
        
        high_value_count = 0
        for info in results:
            if info['confidence'] > 0.5:
                high_value_count += 1
                print(f"\n{high_value_count}. {info['title']}")
                print(f"   åˆ†ç±»: {info['category']} | ç½®ä¿¡åº¦: {info['confidence']:.2f}")
                print(f"   ä½œè€…: {info['author']} | çƒ­åº¦: ğŸ‘{info['likes']} ğŸ’¾{info['collects']} ğŸ’¬{info['comments']}")
                print(f"   ä¼ä¸šå…³é”®è¯: {info['enterprise_keywords']}")
                print(f"   åœ°åŒºå…³é”®è¯: {info['location_keywords']}")
                print(f"   é“¾æ¥: {info['url']}")
        
        # ç»Ÿè®¡åˆ†æ
        print(f"\nğŸ“Š ç»Ÿè®¡åˆ†æ:")
        print(f"æ€»ç¬”è®°æ•°: {len(results)}")
        print(f"é«˜ä»·å€¼ç¬”è®°æ•°: {high_value_count}")
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        category_stats = {}
        for info in results:
            category = info['category']
            category_stats[category] = category_stats.get(category, 0) + 1
        
        print(f"\nğŸ“ˆ åˆ†ç±»ç»Ÿè®¡:")
        for category, count in sorted(category_stats.items(), key=lambda x: x[1], reverse=True):
            print(f"  {category}: {count} æ¡")
        
        # æ¨èå…³æ³¨çš„ä¼ä¸šä¿¡æ¯
        print(f"\nğŸ¯ æ¨èå…³æ³¨çš„ä¼ä¸šä¿¡æ¯:")
        company_notes = [info for info in results if info['category'] == 'company' and info['confidence'] > 0.6]
        recruitment_notes = [info for info in results if info['category'] == 'recruitment' and info['confidence'] > 0.6]
        tech_notes = [info for info in results if info['category'] == 'technology' and info['confidence'] > 0.6]
        
        if company_notes:
            print(f"  ğŸ¢ ä¼ä¸šä¿¡æ¯: {len(company_notes)} æ¡")
            for info in company_notes[:3]:
                print(f"    - {info['title']} (ğŸ‘{info['likes']})")
        
        if recruitment_notes:
            print(f"  ğŸ‘” æ‹›è˜ä¿¡æ¯: {len(recruitment_notes)} æ¡")
            for info in recruitment_notes[:3]:
                print(f"    - {info['title']} (ğŸ‘{info['likes']})")
        
        if tech_notes:
            print(f"  ğŸ’» æŠ€æœ¯ä¿¡æ¯: {len(tech_notes)} æ¡")
            for info in tech_notes[:3]:
                print(f"    - {info['title']} (ğŸ‘{info['likes']})")

if __name__ == "__main__":
    analyze_enterprise_notes() 